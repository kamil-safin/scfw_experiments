{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import scfw.kl as kl\n",
    "from scfw.frank_wolfe import frank_wolfe\n",
    "from scfw.scopt import scopt\n",
    "from scfw.prox_grad import prox_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data'\n",
    "results_folder = './results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run FW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fw(problem_name):\n",
    "    results = {problem_name: {}}\n",
    "    results_file = os.path.join(results_folder,'kl',problem_name+'.pckl')\n",
    "    results = {problem_name: {}}\n",
    "    if os.path.isfile(results_file):\n",
    "        with open(results_file, \"rb\") as f:\n",
    "            results=pickle.load(f)\n",
    "    W, y = load_svmlight_file(os.path.join(data_folder, problem_name))\n",
    "    y = y.reshape(-1, 1)\n",
    "    W = W.toarray()\n",
    "    W = matlib.repmat(y, 1, W.shape[1]) * W\n",
    "    sA = np.sum(W, 1)\n",
    "    W[sA < 0, :] = -W[sA < 0, :]\n",
    "    W = W[sA != 0, :]\n",
    "    Bias = 1\n",
    "    b = (Bias * y).squeeze()\n",
    "    b = np.abs(b)\n",
    "    if (b.any == 0):\n",
    "        print(' Input parameter y error')\n",
    "    y = b\n",
    "    N, n = W.shape\n",
    "    #lam =  np.sqrt(n)/2\n",
    "    lam =  0.005\n",
    "    Mf = 1\n",
    "    nu = 4\n",
    "    R = 30\n",
    "    x0 = np.hstack((np.ones(n) / n, R))\n",
    "    terminate_tol = 1e-15\n",
    "    FW_params={\n",
    "        'iter_FW': 50000,\n",
    "        'line_search_tol': 1e-10,\n",
    "    }\n",
    "    prox_params={\n",
    "        #parameters for SCOPT\n",
    "        'iter_prox': 10000,\n",
    "        'Lest': 'estimate',#,'estimate', #estimate L\n",
    "        'bb_type': 3,\n",
    "        #FISTA parameters\n",
    "        'fista_type': 'fista',\n",
    "        'fista_tol': 1e-5,\n",
    "        'fista_iter': 1000,\n",
    "        'btk_iters': 100,\n",
    "        'backtracking': True\n",
    "    }\n",
    "    func_x = lambda x: kl.val(W, y, lam, x)\n",
    "    func_beta = lambda x, s, beta, dot_product, dot_product_s: kl.val(W, y, lam, (1 - beta) * x + beta * s, (1 - beta) * dot_product + beta * dot_product_s)\n",
    "    grad_x = lambda x, dot_product: kl.grad(W, y, lam, x, dot_product)\n",
    "    grad_beta = lambda x, s, beta, dot_product, dot_product_s: kl.grad(W, y, lam, (1 - beta) * x + beta * s, (1 - beta) * dot_product + beta * dot_product_s)\n",
    "    hess_mult_x = lambda x, dot_product: kl.hess_mult(W, y, lam, x, dot_product)\n",
    "    hess_mult_vec_x = lambda s, dot_product: kl.hess_mult_vec(W, y, lam, s, dot_product)\n",
    "    extra_func = lambda x: W @ x[:-1]\n",
    "    linear_oracle = lambda grad, x: kl.linear_oracle(grad, x)\n",
    "    prox_func = lambda s, L, x: kl.projection(s, x)\n",
    "    #prox_func = lambda s, L: np.maximum(s, 0)\n",
    "    policy_list = ['sc', 'backtracking', 'line_search']\n",
    "    for policy in policy_list:\n",
    "        x, alpha_hist, Gap_hist, Q_hist, time_hist = frank_wolfe(func_x,\n",
    "                                func_beta,                                      \n",
    "                                grad_x,\n",
    "                                grad_beta,\n",
    "                                hess_mult_x,\n",
    "                                extra_func,\n",
    "                                Mf,\n",
    "                                nu,\n",
    "                                linear_oracle,                                                    \n",
    "                                x0,\n",
    "                                FW_params,\n",
    "                                hess=None, \n",
    "                                lloo_oracle=None,                                                 \n",
    "                                alpha_policy=policy,                                                    \n",
    "                                eps=terminate_tol, \n",
    "                                print_every=10000, \n",
    "                                debug_info=False)\n",
    "        results[problem_name][policy] = {\n",
    "            'x': x,\n",
    "            'alpha_hist': alpha_hist,\n",
    "            'Q_hist': Q_hist,\n",
    "            'time_hist': time_hist,\n",
    "        }\n",
    "    print('Prox grad started')\n",
    "    x, alpha_hist, Q_hist, time_hist = prox_grad(func_x,\n",
    "                grad_x,\n",
    "                prox_func,\n",
    "                Mf,\n",
    "                x0,\n",
    "                prox_params,\n",
    "                eps=terminate_tol,\n",
    "                print_every=1000)\n",
    "\n",
    "    results[problem_name]['prox_grad'] = {\n",
    "            'x': x,\n",
    "            'alpha_hist': alpha_hist,\n",
    "            'Q_hist': Q_hist,\n",
    "            'time_hist': time_hist,\n",
    "        }\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "********* Algorithm starts *********\niter=1, stepsize=1.72e-07, criterion=2.44e-07, upper_bound=-11682.119139451102, lower_bound=-2036881.5022619397, real_Gap=2.03e+06, f_val=-11682.119139451102\niter=10000, stepsize=2.74e-07, criterion=2.44e-07, upper_bound=-15609.138687206325, lower_bound=-1609421.7729409698, real_Gap=1.59e+06, f_val=-15609.138687206325\niter=20000, stepsize=4.37e-07, criterion=2.44e-07, upper_bound=-20357.404889443333, lower_bound=-1182847.947007085, real_Gap=1.16e+06, f_val=-20357.404889443333\niter=30000, stepsize=6.86e-07, criterion=2.44e-07, upper_bound=-25496.52284453637, lower_bound=-778516.7684981711, real_Gap=7.53e+05, f_val=-25496.52284453637\niter=40000, stepsize=1.09e-06, criterion=2.44e-07, upper_bound=-30156.646802934967, lower_bound=-384761.5069818148, real_Gap=3.55e+05, f_val=-30156.646802934967\niter=50000, stepsize=1.60e-05, criterion=2.44e-07, upper_bound=-32503.903266081146, lower_bound=-36564.05425510102, real_Gap=4.06e+03, f_val=-32503.903266081146\n257.09182476997375\n********* Algorithm starts *********\niter=1, stepsize=1.72e-02, criterion=1.00e-05, upper_bound=-11682.119139451102, lower_bound=-2036881.5022619397, real_Gap=2.03e+06, f_val=-11682.119139451102\niter=10000, stepsize=1.67e-05, criterion=1.35e-06, upper_bound=-32555.2108775242, lower_bound=-32568.272461937486, real_Gap=1.31e+01, f_val=-32555.2108775242\niter=20000, stepsize=3.23e-05, criterion=1.35e-06, upper_bound=-32556.5254113814, lower_bound=-32567.021156203773, real_Gap=1.05e+01, f_val=-32556.5254113814\niter=30000, stepsize=4.25e-06, criterion=1.35e-06, upper_bound=-32557.4701622563, lower_bound=-32565.81075071875, real_Gap=8.34e+00, f_val=-32557.4701622563\niter=40000, stepsize=1.76e-05, criterion=1.35e-06, upper_bound=-32558.13584558322, lower_bound=-32564.66553299925, real_Gap=6.53e+00, f_val=-32558.13584558322\niter=50000, stepsize=2.14e-06, criterion=1.35e-06, upper_bound=-32558.64052705071, lower_bound=-32564.15126455649, real_Gap=5.51e+00, f_val=-32558.64052705071\n456.1971311569214\n********* Algorithm starts *********\niter=1, stepsize=2.97e-02, criterion=1.00e-05, upper_bound=-11682.119139451102, lower_bound=-2036881.5022619397, real_Gap=2.03e+06, f_val=-11682.119139451102\niter=10000, stepsize=2.23e-05, criterion=9.80e-08, upper_bound=-32560.690405744765, lower_bound=-32561.276514625977, real_Gap=5.86e-01, f_val=-32560.690405744765\niter=20000, stepsize=4.54e-07, criterion=9.80e-08, upper_bound=-32560.700843768518, lower_bound=-32561.273943804918, real_Gap=5.73e-01, f_val=-32560.700843768518\niter=30000, stepsize=1.28e-06, criterion=8.58e-08, upper_bound=-32560.71058147165, lower_bound=-32561.25779217057, real_Gap=5.47e-01, f_val=-32560.71058147165\niter=40000, stepsize=1.96e-07, criterion=8.58e-08, upper_bound=-32560.719581066296, lower_bound=-32561.25779217057, real_Gap=5.38e-01, f_val=-32560.719581066296\niter=50000, stepsize=2.44e-06, criterion=8.58e-08, upper_bound=-32560.728071599417, lower_bound=-32561.25779217057, real_Gap=5.30e-01, f_val=-32560.728071599417\n3816.4749631881714\nProx grad started\niter =    1, stepsize = 1.177e-04, rdiff = 9.997e-01 , f = -11682.1\niter = 1000, stepsize = 6.586e-03, rdiff = 5.116e-02 , f = -32478.9\niter = 2000, stepsize = 1.154e-02, rdiff = 4.549e-02 , f = -32437.6\niter = 3000, stepsize = 9.779e-03, rdiff = 4.793e-02 , f = -32463.8\niter = 4000, stepsize = 1.002e-03, rdiff = 3.694e-02 , f = -32316.2\niter = 5000, stepsize = 3.407e-04, rdiff = 9.924e-01 , f = -32049.3\niter = 6000, stepsize = 4.418e-04, rdiff = 9.903e-01 , f = -32318.7\niter = 7000, stepsize = 8.570e-03, rdiff = 3.591e-02 , f = -32301.2\niter = 8000, stepsize = 5.406e-04, rdiff = 4.021e-02 , f = -32364.7\niter = 9000, stepsize = 2.662e-03, rdiff = 3.235e-02 , f = -32224.7\niter = 10000, stepsize = 2.712e-03, rdiff = 3.190e-02 , f = -32176.4\n0.003989219665527344\n"
    }
   ],
   "source": [
    "#data_list =  ['a1a','a2a','a3a', 'a4a', 'a5a', 'a6a','a7a','a8a','a9a']\n",
    "data_list = ['a9a']\n",
    "for problem_name in data_list:\n",
    "    run_fw(problem_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_name = 'a1a'\n",
    "results = {problem_name: {}}\n",
    "W, y = load_svmlight_file(os.path.join(data_folder, problem_name))\n",
    "y = y.reshape(-1, 1)\n",
    "W = W.toarray()\n",
    "\n",
    "# multiplicative multiplication of the structure of the recognizable structure\n",
    "W = matlib.repmat(y, 1, W.shape[1]) * W\n",
    "# summation of feature descriptions\n",
    "sA = np.sum(W, 1)\n",
    "# if the sum of the string is negative, invert it\n",
    "W[sA < 0, :] = -W[sA < 0, :]\n",
    "# zero row deletion\n",
    "W = W[sA != 0, :]\n",
    "# W = scipy.sparse.csr_matrix(W)\n",
    "\n",
    "Bias = 1\n",
    "b = (Bias * y).squeeze()\n",
    "b = np.abs(b)\n",
    "if (b.any == 0):\n",
    "    print(' Input parameter y error')\n",
    "\n",
    "y = b\n",
    "N, n = W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lam =  np.sqrt(N)/2\n",
    "lam =  0.005\n",
    "#first set of parameters\n",
    "Mf = 1\n",
    "nu = 4\n",
    "R = 30\n",
    "#running parameters\n",
    "x0 = np.hstack((np.ones(n) / n, R))\n",
    "terminate_tol = 1e-15\n",
    "\n",
    "FW_params={\n",
    "    'iter_FW': 50000,\n",
    "    'line_search_tol': 1e-10,\n",
    "}\n",
    "\n",
    "prox_params={\n",
    "        #parameters for SCOPT\n",
    "        'iter_prox': 100,\n",
    "        'Lest': 'estimate',#,'estimate', #estimate L\n",
    "        'bb_type': 3,\n",
    "        #FISTA parameters\n",
    "        'fista_type': 'fista',\n",
    "        'fista_tol': 1e-5,\n",
    "        'fista_iter': 1000,\n",
    "        'btk_iters': 100,\n",
    "        'backtracking': False\n",
    "    }\n",
    "\n",
    "sc_params={\n",
    "    #parameters for SCOPT\n",
    "    'iter_SC': 1000,\n",
    "    'Lest': 'estimate', #estimate L\n",
    "    'use_two_phase': True,\n",
    "    #FISTA parameters\n",
    "    'fista_type': 'mfista',\n",
    "    'fista_tol': 1e-5,\n",
    "    'fista_iter': 100,\n",
    "    #Conjugate Gradient Parameters\n",
    "    'conj_grad_tol': 1e-2,\n",
    "    'conj_grad_iter': 100,\n",
    "}\n",
    "\n",
    "func_x = lambda x: kl.val(W, y, lam, x)\n",
    "func_beta = lambda x, s, beta, dot_product, dot_product_s: kl.val(W, y, lam, (1 - beta) * x + beta * s, (1 - beta) * dot_product + beta * dot_product_s)\n",
    "grad_x = lambda x, dot_product: kl.grad(W, y, lam, x, dot_product)\n",
    "grad_beta = lambda x, s, beta, dot_product, dot_product_s: kl.grad(W, y, lam, (1 - beta) * x + beta * s, (1 - beta) * dot_product + beta * dot_product_s)\n",
    "hess_mult_x = lambda x, dot_product: kl.hess_mult(W, y, lam, x, dot_product)\n",
    "hess_mult_vec_x = lambda s, dot_product: kl.hess_mult_vec(W, y, lam, s, dot_product)\n",
    "extra_func = lambda x: W @ x[:-1]\n",
    "linear_oracle = lambda grad, x: kl.linear_oracle(grad, x)\n",
    "#prox_func = lambda s, L: kl.projection(s) #used for SCOPT\n",
    "prox_func = lambda s, L: np.maximum(s, 0) #used for SCOPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "********* Algorithm starts *********\niter=1, stepsize=3.64e-06, criterion=5.15e-06, upper_bound=-588.6651794834256, lower_bound=-98132.92996543148, real_Gap=9.75e+04, f_val=-588.6651794834256\niter=10000, stepsize=3.73e-05, criterion=4.99e-06, upper_bound=-1604.7511456237717, lower_bound=-1605.337481925639, real_Gap=5.86e-01, f_val=-1604.7511456237717\niter=20000, stepsize=3.28e-05, criterion=2.94e-06, upper_bound=-1604.8556047801235, lower_bound=-1605.1980990404174, real_Gap=3.42e-01, f_val=-1604.8556047801235\niter=30000, stepsize=3.14e-06, criterion=2.94e-06, upper_bound=-1604.9052213473462, lower_bound=-1605.116852464407, real_Gap=2.12e-01, f_val=-1604.9052213473462\niter=40000, stepsize=5.36e-05, criterion=2.94e-06, upper_bound=-1604.9330412087918, lower_bound=-1605.0711389655385, real_Gap=1.38e-01, f_val=-1604.9330412087918\niter=50000, stepsize=1.19e-05, criterion=2.94e-06, upper_bound=-1604.949836777485, lower_bound=-1605.0575573570634, real_Gap=1.08e-01, f_val=-1604.949836777485\n9.789119005203247\n"
    }
   ],
   "source": [
    "policy = 'sc'\n",
    "x, alpha_hist, Gap_hist, Q_hist, time_hist = frank_wolfe(func_x,\n",
    "                           func_beta,                                      \n",
    "                           grad_x,\n",
    "                           grad_beta,\n",
    "                           hess_mult_x,\n",
    "                           extra_func,\n",
    "                           Mf,\n",
    "                           nu,\n",
    "                           linear_oracle,                                                    \n",
    "                           x0,\n",
    "                           FW_params,\n",
    "                           hess=None, \n",
    "                           lloo_oracle=None,                                                 \n",
    "                           alpha_policy=policy,                                                    \n",
    "                           eps=terminate_tol, \n",
    "                           print_every=10000, \n",
    "                           debug_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5.949932622227108"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iter =    1, stepsize = 1.956e-03, rdiff = 9.997e-01 , f = -588.665\niter =   10, stepsize = 4.184e-04, rdiff = 7.473e-01 , f = -979.745\niter =   20, stepsize = 5.456e-04, rdiff = 6.355e-01 , f = -1217.7\niter =   30, stepsize = 6.510e-04, rdiff = 5.904e-01 , f = -1408.02\niter =   40, stepsize = 7.732e-04, rdiff = 5.092e-01 , f = -1535.91\niter =   50, stepsize = 1.020e-03, rdiff = 3.831e-01 , f = -1588.39\niter =   60, stepsize = 1.417e-02, rdiff = 2.923e-01 , f = -1603.08\niter =   70, stepsize = 4.112e-02, rdiff = 3.201e-01 , f = -1583.54\niter =   80, stepsize = 1.307e-01, rdiff = 4.112e-01 , f = -1525.26\niter =   90, stepsize = 1.601e-01, rdiff = 9.727e-01 , f = -885.107\niter =  100, stepsize = 4.050e-02, rdiff = 9.810e-01 , f = -1481.8\n0.0009975433349609375\n"
    }
   ],
   "source": [
    "def proj_simplex(y):\n",
    "    ind = np.argsort(y)\n",
    "    sum_y = sum(y)\n",
    "    origin_y = sum_y\n",
    "    n = len(y)\n",
    "    Py = y.copy()\n",
    "    for i in range(n):\n",
    "        t = (sum_y - 1) / (n - i)\n",
    "        if (origin_y > 1 and t < 0): #for numerical errors\n",
    "            sum_y = sum(y[ind[i : n - 1]])\n",
    "            t = (sum_y - 1) / (n - i)\n",
    "        if i > 0:\n",
    "            if t <= y[ind[i]] and t >= y[ind[i - 1]]:\n",
    "                break\n",
    "        elif t <= y[ind[i]]:\n",
    "            break\n",
    "        sum_y -= y[ind[i]]\n",
    "        Py[ind[i]] = 0\n",
    "    Py = np.maximum(y - t, np.zeros(n))\n",
    "    return Py\n",
    "\n",
    "def projection(y):\n",
    "    t = y[-1]\n",
    "    y = y[:-1]\n",
    "    P_y = proj_simplex(y)\n",
    "    P_y = P_y * t\n",
    "    return np.hstack((P_y, np.max((t, 0))))\n",
    "    #return np.hstack((P_y, np.abs(t)))\n",
    "\n",
    "prox_func = lambda s, L: projection(s) #used for SCOPT\n",
    "\n",
    "x, alpha_hist, Q_hist, time_hist = prox_grad(func_x,\n",
    "                grad_x,\n",
    "                prox_func,\n",
    "                Mf,\n",
    "                x0,\n",
    "                prox_params,\n",
    "                eps=terminate_tol,\n",
    "                print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "29.941674449072963"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The value of nu is not valid\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d87d4f8991e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m           \u001b[0msc_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mterminate_tol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m           print_every=1)\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "x, alpha_hist, Q_hist, time_hist = scopt(func_x,\n",
    "          grad_x,\n",
    "          hess_mult_x,\n",
    "          hess_mult_vec_x,\n",
    "          Mf,\n",
    "          nu,\n",
    "          prox_func,\n",
    "          x0,  \n",
    "          sc_params,                                              \n",
    "          eps=terminate_tol,                                              \n",
    "          print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "np.max((-1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 9, 12],\n       [12, 16]])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "np.tensordot(a[1], a[1], axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595140103138",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}