{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.linalg import norm\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\min_{x \\in \\mathbb R^n_+; \\|x\\|_1 \\le M} f(x) = \\sum_{i = 1}^N w_i^T x - \\sum_{i = 1}^N y_i \\ln (w_i^T x) + \\lambda \\|x\\|_1$$\n",
    "\n",
    "$$\\min_{x \\in \\mathbb R^n_+; \\sum_{i}x_i\\le M} f(x) = \\sum_{i = 1}^N w_i^T x - \\sum_{i = 1}^N y_i \\ln (w_i^T x) + \\lambda e^Tx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson(W, y, lam, x):\n",
    "    \"\"\"\n",
    "        W -- object matrix (N x n)\n",
    "        y -- labels (N)\n",
    "        x -- weights (n)\n",
    "        lam -- regularization param\n",
    "    \"\"\" \n",
    "    dot_product = W @ x # N\n",
    "#     print(x)\n",
    "#     print(dot_product, end='\\n\\n')np.where(\n",
    "    fst_term = np.sum(dot_product)\n",
    "    snd_term = y.dot(np.log(dot_product))\n",
    "    return fst_term - snd_term + lam * sum(x), dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla f(x) = \\begin{bmatrix}\\sum_{i=1}^N w_i - \\sum_{i = 1}^N y_i \\frac{w_i}{w_i^T x}+\\lambda e\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grad_poisson_kamil(W, y, x, lam):\n",
    "#     Btm = W.dot(x)  # Btm(i) = a_i^T x\n",
    "#     Par = 1 - y / Btm\n",
    "#     i = list(range(N))\n",
    "#     DPar = scipy.sparse.csr_matrix((Par, (i, i)), shape=(N, N))\n",
    "#     ResM = DPar.dot(W)\n",
    "#     l1_grad = np.array([1 if c >=0 else -1 for c in x])\n",
    "#     Grad = np.array(np.sum(ResM, axis=0)).squeeze() + lam * l1_grad\n",
    "#     return Grad, Btm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_poisson(W, y, lam, x, dot_product=None):\n",
    "    \"\"\"\n",
    "        W -- object matrix (N x n)\n",
    "        y -- labels (N)\n",
    "        x -- weights (n)\n",
    "        lam -- regularization param\n",
    "        btm -- W @ x (N)\n",
    "    \"\"\"\n",
    "    if dot_product is None:\n",
    "        dot_product = np.squeeze(W @ x) # N\n",
    "    mult=(1-(y / dot_product))\n",
    "    x_term = (W.T @ mult) # n\n",
    "    return x_term.T+lam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla^2 f(x) = \\sum_{i = 1}^N y_i \\frac{w_i w_i^T}{(w_i^T x)^2}$$\n",
    "\n",
    "$$(s-x)^T\\nabla^2 f(x)(s-x) = \\sum_{i = 1}^N y_i \\frac{((s-x)^Tw_i)^2}{(w_i^T x)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hess_poisson_kamil(W, y, lam, Btmv):\n",
    "#     Rat = y / (Btmv)**2\n",
    "#     i = range(N)\n",
    "#     DRat = scipy.sparse.csr_matrix((Rat, (i, i)), shape=(N, N))\n",
    "#     Res1 = (W.T.dot(DRat)).dot(W)\n",
    "#     I = np.eye(n)\n",
    "#     Res2 = lam * I\n",
    "#     H = Res1 + Res2\n",
    "#     # Cholesky method for inverse\n",
    "# #     try:\n",
    "# #         L1 = np.linalg.cholesky(H)\n",
    "# #         Lc = L1.T\n",
    "# #     except np.linalg.LinAlgError as err:\n",
    "# #         print('Cholesky decomposition of H is failed! Regularize it ...')\n",
    "# #         mineig = min(np.linalg.eig(H)[0])\n",
    "# #         Lc = np.linalg.cholesky(H + (-mineig + 1e-12) * I).T\n",
    "# #     iL = np.linalg.solve(Lc, I)\n",
    "# #     Hinv = iL.dot(iL.T)\n",
    "# #     H = H.A\n",
    "#     return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hess_poisson(W, y, x,lam, Btm):\n",
    "    \"\"\"\n",
    "        W -- object matrix (N x n)\n",
    "        y -- labels (N)\n",
    "        x -- weights (n)\n",
    "    \"\"\"\n",
    "    denom = 1 / (Btm) # N\n",
    "    snd_einsum = np.multiply(W, denom.reshape(-1, 1))\n",
    "    fst_einsum = y.reshape(-1, 1) * snd_einsum\n",
    "    return np.einsum('ij,ik->jk', fst_einsum, snd_einsum)\n",
    "\n",
    "def hess_mult_vec(W, y, s, Btm):\n",
    "    \"\"\"\n",
    "        W -- object matrix (N x n)\n",
    "        y -- labels (N)\n",
    "        x -- weights (n)\n",
    "    \"\"\"\n",
    "    return (((W @ s)*y)/Btm).dot(W)\n",
    "\n",
    "\n",
    "def hess_mult(W, y, x, Btm):\n",
    "    \"\"\"\n",
    "        W -- object matrix (N x n)\n",
    "        y -- labels (N)\n",
    "        x -- weights (n)\n",
    "    \"\"\"\n",
    "    num=y.dot((W @ x)**2/Btm)\n",
    "    return num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_simplex_full(grad,M,lam):\n",
    "    n=len(grad)\n",
    "    s = np.zeros(n)\n",
    "    i_max = np.argmax(-(grad))\n",
    "    if grad[i_max]*M+lam*M<0:\n",
    "        s[i_max] = -np.sign(grad[i_max])*M # 1 x n\n",
    "    return s    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
